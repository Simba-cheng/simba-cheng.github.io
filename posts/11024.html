<!DOCTYPE html><html lang="zh-CN" color-mode="light"><head><link href="https://fastly.jsdelivr.net/npm/hexo-tag-common@0.2.0/css/index.css" rel="stylesheet"><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><script defer src="/_vercel/insights/script.js"></script><script defer src="/_vercel/speed-insights/script.js"></script><meta name="author" content="yxcheng"><title>Nginx upstream 模块 | 躺着好舒服</title><link rel="apple-touch-icon" href="/images/favicon.png"><link rel="icon" href="/images/favicon.png"><link href="https://fonts.googleapis.com/css?family=Raleway&display=swap" rel="stylesheet"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1886449_67xjft27j1l.css"><link rel="stylesheet" href="/css/figcaption/mac-block.css"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3163875893588085" crossorigin="anonymous"></script><script defer type="text/javascript" src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><link href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" rel="stylesheet"><script defer type="text/javascript" src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="/js/fancybox.js"></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-WB9L6JQGS1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-WB9L6JQGS1")</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script>var html=document.documentElement;const colorMode=localStorage.getItem("color-mode");colorMode&&document.documentElement.setAttribute("color-mode",colorMode)</script><link rel="stylesheet" href="/css/collapse-code.css"><script src="/js/collapse-code.js"></script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="躺着好舒服" type="application/atom+xml"></head><body><div id="app"><div class="header"><div class="avatar"><a href="/"><img no-lazy src="/images/avatar.png" alt=""></a><div class="nickname"><a href="/">躺着好舒服</a></div></div><div class="navbar"><ul><li class="nav-item" data-path="/"><a href="/">首页</a></li><li class="nav-item" data-path="/tags/"><a href="/tags/">标签</a></li><li class="nav-item" data-path="/categories/"><a href="/categories/">分类</a></li><li class="nav-item" data-path="/archives/"><a href="/archives/">归档</a></li><li class="nav-item" data-path="/notes/"><a href="/notes/">Notes</a></li><li class="nav-item" data-path="/adventure/"><a href="/adventure/">冒险乐园</a></li></ul></div></div><script src="/js/activeNav.js"></script><div class="flex-container"><script async type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.10/dist/clipboard.min.js"></script><script src="/js/codeCopy.js"></script><div class="container post-details" id="post-details"><div class="post-content"><div class="post-title">Nginx upstream 模块</div><div class="post-attach"><span class="post-pubtime"><i class="iconfont icon-updatetime mr-10" title="更新时间"></i> 创建时间:2020-09-04 23:17:13&nbsp; 更新时间:2025-04-21 09:14:59 &nbsp;&nbsp; </span><span><span><i class="iconfont icon-edit"></i> 1.8k 字 </span>&nbsp;&nbsp; </span><span class="post-tags"><i class="iconfont icon-tags mr-10" title="标签"></i> <span class="span--tag mr-8"><a href="/tags/nginx/" title="nginx">#nginx&nbsp;</a></span></span></div><div class="markdown-body"><center><a style="font-style:italic" href="javascript:window.location='https://simba--cheng-cn.translate.goog/' + window.location.pathname + '?_x_tr_sl=zh-CN&amp;_x_tr_tl=en&amp;_x_tr_hl=zh-CN&amp;_x_tr_pto=wapp';">This post is also available in English and alternative languages.</a></center><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><br><p>一般情况应用服务器的上游会部署一套nginx集群，用作反向代理、负载均衡，这个是很好的。</p><br><h1 id="upstream容错重试">1. upstream容错重试</h1><p>假设有五台应用服务器（Backend Server），其中两台宕机不可用；这时某nginx发送请求到其中一台（Backend Server），由于其不可用，Backend Server 会超时或返回错误状态码，然后直接返回给Client，这种场景的处理是很不友好的。</p><p>nginx中的upstream模块，不仅可以负载均衡，还能够对上面这种情况容错。</p><p>upstream可以通过判断节点失效状态、自动探测等方式，自动将问题server节点从访问列表中剔除，期间不会再将请求发送到该Server上（直到Server恢复），而将请求发送给下一台Server，如果下一台也有问题，继续往下重试直到所有Server被重试完。</p><br><h2 id="判断节点失效">1.1. 判断节点失效</h2><p>nginx默认判断节点状态通过 connect refuse 和 time out 状态为准，不会以<strong>http状态码</strong>进行判断；它认为，只要能返回<strong>http状态码</strong>说明该节点还可以正常连接。</p><p>PS：如果是业务层面主动返回的500状态码，它就无法区分。</p><br><h2 id="proxy-next-upstream指令">1.2. proxy_next_upstream指令</h2><p>通过 proxy_next_upstream 指令，可以设置对相关<strong>http状态码</strong>的请求重试、容灾。</p><p>语法：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">proxy_next_upstream</span> <span class="literal">error</span> | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | non_idempotent | <span class="literal">off</span> ...;</span><br></pre></td></tr></table></figure><p>默认值：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">proxy_next_upstream</span> <span class="literal">error</span> timeout;</span><br></pre></td></tr></table></figure><p>上下文环境：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http, server, <span class="section">location</span></span><br></pre></td></tr></table></figure><p>参数含义：</p><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>error</td><td>an error occurred while establishing a connection with the server, passing a request to it, or reading the response header;<br><br>在与服务器建立连接、向其传递请求或读取响应头时发生错误。</td></tr><tr><td>timeout</td><td>a timeout has occurred while establishing a connection with the server, passing a request to it, or reading the response header;<br><br>在与服务器建立连接、向其传递请求或读取响应头时发生超时。</td></tr><tr><td>invalid_header</td><td>a server returned an empty or invalid response;<br>服务器返回空的或无效的响应；</td></tr><tr><td>http_500</td><td>a server returned a response with the code 500;<br>后端服务器返回的响应状态码为500</td></tr><tr><td>http_502</td><td>a server returned a response with the code 502;<br>后端服务器返回的响应状态码为502</td></tr><tr><td>http_503</td><td>a server returned a response with the code 503;<br>后端服务器返回的响应状态码为503</td></tr><tr><td>http_504</td><td>a server returned a response with the code 504;<br>后端服务器返回的响应状态码为504</td></tr><tr><td>http_403</td><td>a server returned a response with the code 403;<br>后端服务器返回的响应状态码为403</td></tr><tr><td>http_404</td><td>a server returned a response with the code 404;<br>后端服务器返回的响应状态码为404</td></tr><tr><td>http_429</td><td>a server returned a response with the code 429<br>后端服务器返回的响应状态码为429</td></tr><tr><td>non_idempotent</td><td>normally, requests with a <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc7231#section-4.2.2">non-idempotent</a> method (<code>POST</code>, <code>LOCK</code>, <code>PATCH</code>) are not passed to the next server if a request has been sent to an upstream server (1.9.13); enabling this option explicitly allows retrying such requests;<br><strong>默认POST, LOCK, PATCH 这些会对服务器造成幂等的http请求，不会进行重试。一定要对这些http请求重试，则添加该参数。</strong></td></tr><tr><td>off</td><td>disables passing a request to the next server.<br>停止将请求发送给下一台后端服务器</td></tr></tbody></table><br><h2 id="超时参数">1.3. 超时参数</h2><table><thead><tr><th>参数</th><th>含义</th></tr></thead><tbody><tr><td>proxy_connect_timeout</td><td>与后端服务器建立连接的超时<br>默认值60s</td></tr><tr><td>proxy_send_timeout</td><td>向后端服务器传输请求的超时<br>默认值60s</td></tr><tr><td>proxy_read_timeout</td><td>从后端服务器读取响应的超时<br>默认值60s</td></tr></tbody></table><br><h1 id="Nginx-upstream-负载均衡策略">2. Nginx - upstream - 负载均衡策略</h1><h2 id="普通轮询（round-robin）">2.1. 普通轮询（round-robin）</h2><p>默认策略，每个请求按照时间顺序逐一分配。</p><p>如果某个机器宕机（符合指定异常、状态码），跳过该机器向下一个机器发起重试。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设定负载均衡服务器列表</span></span><br><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.8:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.9:80</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="section">location</span> / &#123;</span><br><span class="line">    	<span class="comment"># 请求转向backend定义的服务器列表</span></span><br><span class="line">        <span class="attribute">proxy_pass</span> http://backend;</span><br><span class="line">        <span class="comment"># 获取到指定异常（http状态码），再进行重试</span></span><br><span class="line">        <span class="attribute">proxy_next_upstream</span> <span class="literal">error</span> http_500 http_502 http_503 http_504;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><h2 id="加权轮询">2.2. 加权轮询</h2><p>weight 指定轮询的权值，weight值越大，分配到的访问机率越高，该策略主要用于后端每个服务器性能不均的情况下。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设定负载均衡服务器列表</span></span><br><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">	<span class="comment"># weigth参数表示权值，权值越高被分配到的几率越大</span></span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.8:80</span> weight=<span class="number">1</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.9:80</span> weight=<span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="section">location</span> / &#123;</span><br><span class="line">        <span class="comment"># 请求转向backend定义的服务器列表</span></span><br><span class="line">        <span class="attribute">proxy_pass</span> http://backend;</span><br><span class="line">        <span class="comment"># 获取到指定异常（http状态码），再进行重试</span></span><br><span class="line">        <span class="attribute">proxy_next_upstream</span> <span class="literal">error</span> http_500 http_502 http_503 http_504;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><h2 id="ip-hash">2.3. ip_hash</h2><p>按照Client Ip的hash结果分配；</p><p>这样来自同一个IP的client固定访问一个Backend Server，可以解决session不能跨服务器的问题。</p><p>当然如果这个节点不可用了，会发到下个节点，而此时没有session同步的话就注销掉了。</p><p>存在局限性，client IP一旦变化，hash值重新计算，可能就换backend server了。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设定负载均衡服务器列表</span></span><br><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">    ip_hash;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.8:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.9:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.10:80</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line"> <span class="section">server</span> &#123;</span><br><span class="line">    <span class="section">location</span> / &#123;</span><br><span class="line">        <span class="comment"># 请求转向backend定义的服务器列表</span></span><br><span class="line">        <span class="attribute">proxy_pass</span> http://backend;</span><br><span class="line">        <span class="comment"># 获取到指定异常（http状态码），再进行重试</span></span><br><span class="line">        <span class="attribute">proxy_next_upstream</span> <span class="literal">error</span> http_500 http_502 http_503 http_504;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><h2 id="least-conn">2.4. least_conn</h2><p>最少连接均衡；</p><p>请求被发送到当前活跃连接最少的后端服务器。会考虑weight的值。如果有多个后端服务器的 conns 值同为最小的，那么对它们采用加权轮询算法（weight）。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">    least_conn;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.8:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.9:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.10:80</span>;</span><br><span class="line"> &#125;</span><br><span class="line">  <span class="section">server</span> &#123;</span><br><span class="line">    <span class="section">location</span> / &#123;</span><br><span class="line">        <span class="comment"># 请求转向backend定义的服务器列表</span></span><br><span class="line">        <span class="attribute">proxy_pass</span> http://backend;</span><br><span class="line">        <span class="comment"># 获取到指定异常（http状态码），再进行重试</span></span><br><span class="line">        <span class="attribute">proxy_next_upstream</span> <span class="literal">error</span> http_500 http_502 http_503 http_504;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><h2 id="sticky">2.5. sticky</h2><p>Nginx的负载均衡-upstream模块，其负载均衡策略有普通轮询、加权轮询、ip_hash、least_conn等几种方式。</p><p>sticky也是负载均衡策略之一（需要引入相应模块），sticky是基于cookie实现负载的。</p><p>通过分发识别cookie，使得来自同一个客户端的请求落在同一台服务器上，默认cookie标识名为route。</p><br><h3 id="sticky-原理">2.5.1. sticky 原理</h3><p><strong>①：</strong> client 首次发起请求，nginx接收后请求头没有cookie，则以轮询的方式分发给Backend Server。</p><p><strong>②：</strong> Backend Server业务处理后返回nginx。</p><p><strong>③：</strong> 此时nginx生成cookie（route），返回client。route值与Backend Server相关联。</p><p><strong>④：</strong> client接收请求并保存带route的cookie。</p><p><strong>⑤：</strong> 当client下次发送请求时，cookie中就会带上route，nginx根据cookie中的route，将这个client的请求转发到固定的Backend Server。</p><br><h3 id="问题">2.5.2. 问题</h3><p>sticky策略在某些场景大流量冲击下，会导致负载不均的情况。</p><p>当年大促，系统被流量冲垮后复盘，发现应用服务器流量不均衡；往上游排查时发现，系统负载的Nginx负载策略是 sticky，这个策略是中间件部门配置的默认参数，公司大部分系统，默认都是这个策略。</p><p>由于当时日志检索系统也存在问题、降级，导致没有采集到关键信息，比如nginx分配的cookie route。</p><p>最后整改方案，将sticky策略，修改成普通的轮询策略。</p><br><h1 id="Reference">3. Reference</h1><p><a target="_blank" rel="noopener" href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream">nginx - proxy_next_upstream</a></p><p><a target="_blank" rel="noopener" href="http://nginx.org/en/docs/http/load_balancing.html">Using nginx as HTTP load balancer</a></p><br><link rel="stylesheet" href="/css/folder.css" type="text/css"><script src="/js/folder.js" type="text/javascript" async></script><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script></div></div><div id="btn-catalog" class="btn-catalog"><i class="iconfont icon-catalog"></i></div><div class="post-catalog hidden" id="catalog"><div class="title">目录</div><div class="catalog-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#upstream%E5%AE%B9%E9%94%99%E9%87%8D%E8%AF%95"><span class="toc-text">1. upstream容错重试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A4%E6%96%AD%E8%8A%82%E7%82%B9%E5%A4%B1%E6%95%88"><span class="toc-text">1.1. 判断节点失效</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#proxy-next-upstream%E6%8C%87%E4%BB%A4"><span class="toc-text">1.2. proxy_next_upstream指令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B6%85%E6%97%B6%E5%8F%82%E6%95%B0"><span class="toc-text">1.3. 超时参数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Nginx-upstream-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5"><span class="toc-text">2. Nginx - upstream - 负载均衡策略</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%99%AE%E9%80%9A%E8%BD%AE%E8%AF%A2%EF%BC%88round-robin%EF%BC%89"><span class="toc-text">2.1. 普通轮询（round-robin）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E6%9D%83%E8%BD%AE%E8%AF%A2"><span class="toc-text">2.2. 加权轮询</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ip-hash"><span class="toc-text">2.3. ip_hash</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#least-conn"><span class="toc-text">2.4. least_conn</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sticky"><span class="toc-text">2.5. sticky</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sticky-%E5%8E%9F%E7%90%86"><span class="toc-text">2.5.1. sticky 原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-text">2.5.2. 问题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Reference"><span class="toc-text">3. Reference</span></a></li></ol></div></div><script src="/js/catalog.js"></script><div class="comments-container"></div></div><div class="footer"><div class="social"><ul><li><a title="github" target="_blank" rel="noopener" href="https://github.com/Simba-cheng"><i class="iconfont icon-github"></i></a></li><li><a title="rss" href="/atom.xml"><i class="iconfont icon-rss"></i></a></li></ul></div><div class="footer-more"><a target="_blank" rel="noopener" href="https://github.com/zchengsite/hexo-theme-oranges">Copyright © 2025 Oranges</a></div><div class="footer-more"><a target="_blank" rel="noopener" href="https://github.com/zchengsite/hexo-theme-oranges">Theme by Oranges | Powered by Hexo</a></div><div class="footer-views">本站总访问量<span id="busuanzi_value_site_pv"></span>次 本文总阅读量<span id="busuanzi_value_page_pv"></span>次 本站访客数<span id="busuanzi_value_site_uv"></span>人</div></div></div><div class="tools-bar"><div class="back-to-top tools-bar-item hidden"><a href="javascript: void(0)"><i class="iconfont icon-chevronup"></i></a></div><script src="/js/backtotop.js"></script><div class="search-icon tools-bar-item" id="search-icon"><a href="javascript: void(0)"><i class="iconfont icon-search"></i></a></div><div class="search-overlay hidden"><div class="search-content" tabindex="0"><div class="search-title"><span class="search-icon-input"><a href="javascript: void(0)"><i class="iconfont icon-search"></i> </a></span><input type="text" class="search-input" id="search-input" placeholder="搜索..."> <span class="search-close-icon" id="search-close-icon"><a href="javascript: void(0)"><i class="iconfont icon-close"></i></a></span></div><div class="search-result" id="search-result"></div></div></div><script type="text/javascript">var inputArea=document.querySelector("#search-input"),searchOverlayArea=document.querySelector(".search-overlay");function openOrHideSearchContent(){searchOverlayArea.classList.contains("hidden")?(searchOverlayArea.classList.remove("hidden"),document.body.classList.add("hidden")):(searchOverlayArea.classList.add("hidden"),document.body.classList.remove("hidden"))}function blurSearchContent(e){e.target===searchOverlayArea&&openOrHideSearchContent()}inputArea.onclick=function(){getSearchFile(),this.onclick=null},inputArea.onkeydown=function(){if(13==event.keyCode)return!1},document.querySelector("#search-icon").addEventListener("click",openOrHideSearchContent,!1),document.querySelector("#search-close-icon").addEventListener("click",openOrHideSearchContent,!1),searchOverlayArea.addEventListener("click",blurSearchContent,!1);var searchFunc=function(e,t,n){"use strict";var r=document.getElementById(t),a=document.getElementById(n);a.innerHTML="<ul><span class='local-search-empty'>首次搜索，正在载入索引文件，请稍后……<span></ul>",$.ajax({url:e,dataType:"xml",success:function(e){var t=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get();a.innerHTML="",r.addEventListener("input",function(){var u='<ul class="search-result-list">',h=this.value.trim().toLowerCase().split(/[\s\-]+/);if(a.innerHTML="",!(this.value.trim().length<=0)){if(t.forEach(function(e){var n,r,a=!0,t=(e.title&&""!==e.title.trim()||(e.title="Untitled"),e.title.trim()),c=t.toLowerCase(),s=e.content.trim().replace(/<[^>]+>/g,""),i=s.toLowerCase(),e=e.url,l=-1,o=-1;""!==i?h.forEach(function(e,t){n=c.indexOf(e),l=i.indexOf(e),n<0&&l<0?a=!1:(l<0&&(l=0),0==t&&(o=l))}):a=!1,a&&(u+="<li><a href='"+e+"' class='search-result-title'>"+t+"</a>",0<=o&&(e=o+80,(e=0==(t=(t=o-20)<0?0:t)?100:e)>s.length&&(e=s.length),r=s.substr(t,e),h.forEach(function(e){var t=new RegExp(e,"gi");r=r.replace(t,'<span class="search-keyword">'+e+"</span>")}),u+='<p class="search-result-abstract">'+r+"...</p>"),u+="</li>")}),-1===(u+="</ul>").indexOf("<li>"))return a.innerHTML="<ul><span class='local-search-empty'>没有找到内容，请尝试更换检索词。<span></ul>";a.innerHTML=u}})},error:function(e,t,n){a.innerHTML="",404===e.status?a.innerHTML="<ul><span class='local-search-empty'>未找到search.xml文件，具体请参考：<a href='https://github.com/zchengsite/hexo-theme-oranges#configuration' target='_black'>configuration</a><span></ul>":a.innerHTML="<ul><span class='local-search-empty'>请求失败，尝试重新刷新页面或稍后重试。<span></ul>"}}),$(document).on("click","#search-close-icon",function(){$("#search-input").val(""),$("#search-result").html("")})},getSearchFile=function(){searchFunc("/search.xml","search-input","search-result")}</script><div class="tools-bar-item theme-icon" id="switch-color-scheme"><a href="javascript: void(0)"><i id="theme-icon" class="iconfont icon-moon"></i></a></div><script src="/js/colorscheme.js"></script><div class="share-icon tools-bar-item"><a href="javascript: void(0)" id="share-icon"><i class="iconfont iconshare"></i></a><div class="share-content hidden"><a class="share-item" href="https://twitter.com/intent/tweet?text=' + Nginx%20upstream%20%E6%A8%A1%E5%9D%97 + '&url=' + https%3A%2F%2Fsimba-cheng.github.io%2Fposts%2F11024.html + '" target="_blank" title="Twitter"><i class="iconfont icon-twitter"></i> </a><a class="share-item" href="https://www.facebook.com/sharer.php?u=https://simba-cheng.github.io/posts/11024.html" target="_blank" title="Facebook"><i class="iconfont icon-facebooksquare"></i></a></div></div><script src="/js/shares.js"></script></div></div><script src="https://fastly.jsdelivr.net/npm/hexo-tag-common@0.2.0/js/index.js"></script><style>[bg-lazy]{background-image:none!important;background-color:#eee!important}</style><script>window.imageLazyLoadSetting={isSPA:!1,preloadRatio:3,processImages:null}</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})})</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a=c[o],i=function(){c=c.filter(function(t){return a!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(a)};(t=a).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),i()):(e=new Image,n=t.getAttribute("data-original"),e.onload=function(){t.src=n,t.removeAttribute("data-original"),i()},t.src!==n&&(e.src=n))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this)</script><script src="/js/markmap.js"></script></body></html>